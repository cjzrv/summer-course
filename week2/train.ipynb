{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 homework\n",
    "Please train a model with PyTorch to classify Fashion MNIST dataset, and submit your source code for training, your best model, and the screenshot of the training log (not required if your jupyter notebook contains the training log).\n",
    "\n",
    "Your source code must contain custom dataset, data normalization, data augmentation, loss & accuracy calculations on training / validation / testing set.\n",
    "  \n",
    "Deadline: 2024/08/13 23:59:59\n",
    "\n",
    "本程式用到的檔案放在我的 GitHub repository：  \n",
    "https://github.com/cjzrv/summer-course/tree/main/week2\n",
    "\n",
    "fashion-mnist_train.csv 及 fashion-mnist_test.csv 須自行下載後放置到 fashion 目錄下：  \n",
    "https://www.kaggle.com/datasets/zalando-research/fashionmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 匯入需要的套件及模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將資料集轉換為圖片\n",
    "\n",
    "由於 Fashion MNIST 資料集是以 CSV 檔案形式提供，我想先將這些資料還原回圖片格式，以模擬之後自己建立資料集時使用圖片作為輸入的情況。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\n",
    "    'T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "\n",
    "# 轉換 training dataset 裡的資料為圖片檔，並把 label 作為檔名\n",
    "csv_file_path = './fashion/fashion-mnist_train.csv'\n",
    "output_dir = 'images/train'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "labels = data.iloc[:, 0].values\n",
    "images = data.iloc[:, 1:].values\n",
    "\n",
    "for i in range(len(images)):\n",
    "    image_array = images[i].reshape(28, 28)\n",
    "    label = labels[i]\n",
    "    \n",
    "    image = Image.fromarray(image_array.astype(np.uint8))\n",
    "    label_name = label_names[label]\n",
    "    \n",
    "    image.save(os.path.join(output_dir, f'label_{label}_{label_name}_{i}.png'))\n",
    "\n",
    "# 轉換 testing dataset 裡的資料為圖片檔，並把 label 作為檔名\n",
    "csv_file_path = './fashion/fashion-mnist_test.csv'\n",
    "output_dir = 'images/test'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "labels = data.iloc[:, 0].values\n",
    "images = data.iloc[:, 1:].values\n",
    "\n",
    "for i in range(len(images)):\n",
    "    image_array = images[i].reshape(28, 28)\n",
    "    label = labels[i]\n",
    "    \n",
    "    image = Image.fromarray(image_array.astype(np.uint8))\n",
    "    label_name = label_names[label]\n",
    "    \n",
    "    image.save(os.path.join(output_dir, f'label_{label}_{label_name}_{i}.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 增加額外的訓練資料\n",
    "\n",
    "我拍了幾張自己的衣服、褲子還有拖鞋的照片，雖然不夠 fashion 但我還是把它們加進了這次的訓練資料集中。\n",
    "\n",
    "（我已在這些照片的檔名上標好了 label）\n",
    "\n",
    "轉換前：\n",
    "\n",
    "<img src=\"./showcase/before.png\" alt=\"before\" width=\"500px\"/>\n",
    "\n",
    "轉換後：\n",
    "\n",
    "<img src=\"./showcase/after.png\" alt=\"after\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = './pic'\n",
    "output_folder = './images/train'      # 輸出到跟訓練資料集一樣的目錄下\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = Image.open(img_path).convert('RGBA')\n",
    "        \n",
    "        np_img = np.array(img)\n",
    "        r, g, b, a = np.rollaxis(np_img, axis=-1)\n",
    "        mask = ((r > 240) & (g > 240) & (b > 240))\n",
    "        np_img[mask] = [0, 0, 0, 0]\n",
    "        \n",
    "        img_no_bg = Image.fromarray(np_img, 'RGBA')\n",
    "\n",
    "        img_gray = ImageOps.grayscale(img_no_bg)\n",
    "        img_black_bg = Image.new(\"L\", img_gray.size, 0)\n",
    "        img_black_bg.paste(img_gray, (0, 0), img_no_bg)\n",
    "        \n",
    "        img_resized = img_black_bg.resize((28, 28))\n",
    "        \n",
    "        img_inverted = ImageOps.invert(img_resized)\n",
    "        enhancer = ImageEnhance.Contrast(img_inverted)\n",
    "        img_contrast = enhancer.enhance(2.0)\n",
    "\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        img_contrast.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義這次訓練所要使用的模型\n",
    "\n",
    "就是一個簡單的 CNN 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=256 * 3 * 3, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.nn.functional.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.nn.functional.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(torch.nn.functional.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        x = x.view(-1, 256 * 3 * 3)\n",
    "        \n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自訂一個資料集的類別\n",
    "\n",
    "能夠直接以圖片的格式載入資料集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir                  # read data from the image folder\n",
    "        self.transform = transform                  # initial transfrom\n",
    "\n",
    "        # 取得所有圖片的檔名\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n",
    "\n",
    "        # 取檔名的第二部份作為 label（前面就是這樣命名的）\n",
    "        self.labels = [int(f.split('_')[1]) for f in self.image_files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料預處理\n",
    "\n",
    "經過多次測試，資料增強方法的參數若設置過大，反而會嚴重降低模型預測的準確率，故這裡都是選用較小的參數。\n",
    "\n",
    "在選擇資料增強的方法時也需注意該方法是否適合要處理的資料集，如辨識手寫數字時，若使用垂直翻轉，6 就直接變成 9 了。\n",
    "\n",
    "而對一些不對稱的數字用水平翻轉（如 5），得出的額外資料也不能幫助模型的訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),                      # 隨機旋轉\n",
    "    transforms.RandomResizedCrop(size=28, scale=(0.9, 1.1)),    # 隨機縮放\n",
    "    transforms.RandomHorizontalFlip(p=0.3),                     # 隨機水平翻轉\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),       # 隨機調整亮度和對比度\n",
    "    transforms.ToTensor(),                  # 將原來 [0, 255] 的像素值轉成範圍在 [0, 1] 的張量格式\n",
    "    transforms.Normalize((0.5,), (0.5,)),   # 再對 [0, 1] 的像素值做標準化，輸出的範圍為 [-1, 1]，這麼做能夠加速模型收斂\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                  # 測試資料集不需進行資料增強\n",
    "    transforms.Normalize((0.5,), (0.5,))    # 但仍需將圖像轉換為張量並進行標準化，使測試時的輸入格式保持一致\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料集\n",
    "\n",
    "載入訓練資料集和測試資料集並切割出一個驗證資料集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'images/train'\n",
    "test_path = 'images/test'\n",
    "\n",
    "train_data = FashionDataset(image_dir=train_path, transform=train_transform)\n",
    "test_data = FashionDataset(image_dir=test_path, transform=test_transform)\n",
    "testLen = int(len(test_data) * 0.5)             # 因為 fashion mnist 沒有提供 validation dataset\n",
    "valLen = len(test_data) - testLen               # 故我們手動切割一半的 testing dataset 為 validation dataset\n",
    "test_data, val_data = random_split(test_data, [testLen, valLen])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 選擇用於計算的裝置\n",
    "\n",
    "有 GPU 就用 GPU，沒有就用 CPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 選擇 loss function 和 optimizer 的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2304, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()                       # loss funtion 選擇 CrossEntropyLoss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001)  # optimizer 選擇 AdamW，lr 為 learning rate\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 0.7157, Training Accuracy: 0.7495\n",
      "** Validation Loss: 0.3850, Validation Accuracy: 0.8608 **\n",
      "Epoch 2/20, Training Loss: 0.4533, Training Accuracy: 0.8363\n",
      "** Validation Loss: 0.3362, Validation Accuracy: 0.8736 **\n",
      "Epoch 3/20, Training Loss: 0.3960, Training Accuracy: 0.8563\n",
      "** Validation Loss: 0.2917, Validation Accuracy: 0.8924 **\n",
      "Epoch 4/20, Training Loss: 0.3639, Training Accuracy: 0.8668\n",
      "** Validation Loss: 0.2720, Validation Accuracy: 0.8958 **\n",
      "Epoch 5/20, Training Loss: 0.3414, Training Accuracy: 0.8757\n",
      "** Validation Loss: 0.2757, Validation Accuracy: 0.8946 **\n",
      "Epoch 6/20, Training Loss: 0.3238, Training Accuracy: 0.8822\n",
      "** Validation Loss: 0.2548, Validation Accuracy: 0.9032 **\n",
      "Epoch 7/20, Training Loss: 0.3117, Training Accuracy: 0.8860\n",
      "** Validation Loss: 0.2342, Validation Accuracy: 0.9126 **\n",
      "Epoch 8/20, Training Loss: 0.3003, Training Accuracy: 0.8896\n",
      "** Validation Loss: 0.2366, Validation Accuracy: 0.9120 **\n",
      "Epoch 9/20, Training Loss: 0.2906, Training Accuracy: 0.8937\n",
      "** Validation Loss: 0.2347, Validation Accuracy: 0.9140 **\n",
      "Epoch 10/20, Training Loss: 0.2830, Training Accuracy: 0.8962\n",
      "** Validation Loss: 0.2303, Validation Accuracy: 0.9120 **\n",
      "Epoch 11/20, Training Loss: 0.2766, Training Accuracy: 0.8986\n",
      "** Validation Loss: 0.2120, Validation Accuracy: 0.9202 **\n",
      "Epoch 12/20, Training Loss: 0.2719, Training Accuracy: 0.9007\n",
      "** Validation Loss: 0.2125, Validation Accuracy: 0.9222 **\n",
      "Epoch 13/20, Training Loss: 0.2646, Training Accuracy: 0.9039\n",
      "** Validation Loss: 0.2131, Validation Accuracy: 0.9170 **\n",
      "Epoch 14/20, Training Loss: 0.2597, Training Accuracy: 0.9052\n",
      "** Validation Loss: 0.2062, Validation Accuracy: 0.9234 **\n",
      "Epoch 15/20, Training Loss: 0.2538, Training Accuracy: 0.9064\n",
      "** Validation Loss: 0.2075, Validation Accuracy: 0.9190 **\n",
      "Epoch 16/20, Training Loss: 0.2534, Training Accuracy: 0.9061\n",
      "** Validation Loss: 0.2053, Validation Accuracy: 0.9206 **\n",
      "Epoch 17/20, Training Loss: 0.2455, Training Accuracy: 0.9102\n",
      "** Validation Loss: 0.2026, Validation Accuracy: 0.9236 **\n",
      "Epoch 18/20, Training Loss: 0.2412, Training Accuracy: 0.9118\n",
      "** Validation Loss: 0.2122, Validation Accuracy: 0.9222 **\n",
      "Epoch 19/20, Training Loss: 0.2391, Training Accuracy: 0.9128\n",
      "** Validation Loss: 0.2030, Validation Accuracy: 0.9236 **\n",
      "Epoch 20/20, Training Loss: 0.2329, Training Accuracy: 0.9138\n",
      "** Validation Loss: 0.1979, Validation Accuracy: 0.9272 **\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20                             # 對訓練集完整訓練一次為一個 epoch\n",
    "best_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()               # 將梯度歸零，避免累加到先前計算的梯度\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)   # 用前面設定的 loss function 對 output 和 label 計算出 loss 值\n",
    "        loss.backward()                     # 進行 backpropagation，計算每個參數的梯度\n",
    "        optimizer.step()                    # 使用計算出的梯度來更新模型的參數\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)    # loss.item() 為當前 batch 的 loss 值\n",
    "                                                        # input.size() 等同於這次訓練的 batch size\n",
    "                                                        # 把當前 batch 的 loss 累加到這個 epoch 的總 loss 中\n",
    "        _, predicted = torch.max(outputs, 1)            # torch.max(outputs, 1) 會回傳預測機率的最大值和最大值所在的索引\n",
    "                                                        # 這邊不需要用到預測機率的最大值，故回傳到 _ 變數並無視它\n",
    "                                                        # predicted 則保存最大值所在的索引，也就是預測出的結果\n",
    "        total_train += labels.size(0)                           # 把總訓練數加上這次訓練的 batch size\n",
    "        correct_train += (predicted == labels).sum().item()     # correct_train 會累計當前這個 epoch 預測正確的總樣本數\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)       # train_loss 為當前這個 epoch 的平均 loss\n",
    "    train_accuracy = correct_train / total_train                # train_accuracy 為當前這個 epoch 的平均準確率\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    # 使用 validation dataset 對模型進行測試\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = correct_val / total_val\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            # 保存得出最佳結果的模型參數\n",
    "            torch.save(model.state_dict(), 'best.pth')\n",
    "            best_accuracy = val_accuracy\n",
    "\n",
    "        print(f\"** Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f} **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評估模型\n",
    "\n",
    "使用測試資料集對訓練出的最佳模型參數進行測試，以評估其性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss: 0.1895, Testing Accuracy: 0.9340\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best.pth', weights_only=False))\n",
    "\n",
    "model.eval()\n",
    "running_test_loss = 0.0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_test_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss = running_test_loss / len(test_loader.dataset)\n",
    "test_accuracy = correct_test / total_test\n",
    "\n",
    "print(f'Testing Loss: {test_loss:.4f}, Testing Accuracy: {test_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
